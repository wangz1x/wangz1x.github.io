<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Centos7开放防火墙端口]]></title>
    <url>%2F2018%2F09%2F17%2FCentos7%E5%BC%80%E6%94%BE%E9%98%B2%E7%81%AB%E5%A2%99%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[Centos7之前一般是用iptables管理防火墙相关内容的，一般用到的就是开放一个端口供我们的应用使用，其命令如下:iptables -I INPUT -p tcp --dport 11111 -j ACCEPT 添加端口: 删除端口: Centos7一般新增了firewall-cmd，用来管理防火墙首先开启systemctl start firewalld 查看状态firewall-cmd --state 添加端口firewall-cmd --add-port=11111/tcp --zone=public --permanent 查看端口firewall-cmd --list-ports 添加端口后一般是用 firewall-cmd --reload来更新使其生效 firewall中的zone，不知道和iptables中的chain有没有关系，用firewall-cmd添加的端口在iptables -L -n中也可以看到(好像是废话- -) 删除端口firewall-cmd --remove-port=11111/tcp 基本的使用over.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman Coding]]></title>
    <url>%2F2018%2F09%2F17%2FHuffman-Coding%2F</url>
    <content type="text"><![CDATA[前两天做笔试题时碰到了久违的哈夫曼编码, 想当初还用c实现过了, 但是做题的时候突然就忘了哈夫曼的实现过程- -，下面记录一下具体的步骤。 过程 计算各个待编码字符出现的频率. 比如HELLOWORLD，一共10个字符，H E W R D各1次，L3次，O2次，各自出现的频率就是次数/总数。 在频率中找最小的两个值，相加，结果放进频率集中。这样做的目的是，频率越小，说明出现的次数相对越少，那么在进行Huffman编码时，这些小频率的字符就在Huffman树的底层，则生成的编码就越长，相对的，频率高的就出现在Huffman树的高层，生成的编码越短，这样就可能起到压缩的效果。例如当前的频率集为0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.3，选取两个0.1进行操作，新的频率集为0.1, 0.1, 0.1, 0.2, 0.2, 0.3。 构造Huffman树: 重复第二步直到构造出完整的Huffman树，接下来就是编码了，很简单，左右子树分别标记为0/1，如下图:每个字符的编码就是从根节点到该节点路径上的标识，比如W为000，H为1010。 总结流程大概就是这样，从图中也可以看出来，Huffman编码是一种前缀编码，即每个编码不会是另外编码的前缀，因为每个字符都是叶子节点，如果有一个编码是其他编码的前缀，那么该编码的字符一定不是叶子节点。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>huffman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查漏]]></title>
    <url>%2F2018%2F09%2F12%2F%E6%9F%A5%E6%BC%8F%2F</url>
    <content type="text"><![CDATA[Java类库中的I/O类分成输入和输出两部分, 可以在JDK文档的类层次结构中看到。通过继承, 任何自InputStream和Reader派生而来的类都含有名为read的基本方法, 用于读取单个字节或字节数组。同样, 任何继承自OutputStream和Writer而来的类都含有名为write的基本方法, 用于写单个字节或字节数组。我们很少使用单一的类来创建流对象, 而是通过叠合多个对象来提供所期望的功能, 也就是类外套上其他的类, 即装饰器设计模式。 InputStreamInputStream的作用是用来表示那些从不同数据源产生输入的类。这些数据源包括但不限于: 字节数组 String对象 文件 管道, 工作方式和实际管道类似, 从一端输入, 从另一端输出 这些数据源都有对应的InputStream子类, 一般称为介质流: ByteArrayInputStream StringBufferInputStream(Deprecated) FileInputStream PipedInputStream 可以把以上输入流归为介质流, 因为这些流是和具体的源数据打交道的。另外, FilterInputStream也是一种输入流, 只不过它是套在介质流之外的, 可以称作包装流/过滤流, 主要有以下几种: BufferedInputStream DataInputStream PushbackInputStream OutputStream和InputStream对应, OutputStream流中的介质流也主要有以下几种: ByteArrayOutputStream FileOutputStream PipedOutputStream 包装流/过滤流主要有: BufferedOutputStream DataOutputStream PrintStream other如何按照指定编码读取文件? 读取文件一般就想到用FileInputStream, 但是我们看下它的构造方法, 并没有提供”编码”这项功能, 其实基本上字节流都没有指定编码这项功能, 在一番查找下, 才最终在InputStreamReader中找到了charset 12345678910111213141516171819202122public InputStreamReader(InputStream in, String charsetName) throws UnsupportedEncodingException&#123; super(in); if (charsetName == null) throw new NullPointerException("charsetName"); sd = StreamDecoder.forInputStreamReader(in, this, charsetName);&#125;public InputStreamReader(InputStream in, Charset cs) &#123; super(in); if (cs == null) throw new NullPointerException("charset"); sd = StreamDecoder.forInputStreamReader(in, this, cs);&#125;public InputStreamReader(InputStream in, CharsetDecoder dec) &#123; super(in); if (dec == null) throw new NullPointerException("charset decoder"); sd = StreamDecoder.forInputStreamReader(in, this, dec);&#125; 说到编码, 其实String类的构造函数中也提供了指定编码的功能: 123456public String(byte bytes[], int offset, int length, Charset charset) &#123; if (charset == null) throw new NullPointerException("charset"); checkBounds(bytes, offset, length); this.value = StringCoding.decode(charset, bytes, offset, length);&#125; InputStreamReader和OutputStreamWriter是连接字节流和字符流的桥梁:InputStreamReader用指定的编码或者默认平台编码从字节中读取数据并把他们解码为字符OutputStreamWriter用指定的编码或默认平台编码把写入的字符编码为相应的字节 如何采用”追加”方式向文件中写东西?这个平时还真没注意, 但是在c或python我还记得是以a方式打开文件, 然后翻了FileOutputStream发现java中并没有所谓的”方式”, 在write方法中会隐藏一个append字段: 123456789101112public void write(byte b[]) throws IOException &#123; writeBytes(b, 0, b.length, append);&#125;public void write(byte b[], int off, int len) throws IOException &#123; writeBytes(b, off, len, append);&#125;private native void writeBytes(byte b[], int off, int len, boolean append) throws IOException;...... 那么这个字段值是在哪指定的呢? 再看它的构造函数: 123public FileOutputStream(File file, boolean append)&#123;&#125;public FileOutputStream(String name, boolean append)&#123;&#125; 在构造文件输出流时就会让你选择是否以追加的模式构建流.]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dijkstra-单源最短路径问题]]></title>
    <url>%2F2018%2F09%2F08%2FDijkstra-%E5%8D%95%E6%BA%90%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[关于图论中的算法大多还是数据结构课上讲的, 过了这么久突然想起来, 就来复习复习吧。这里看一下Dijkstra算法再有向图中的使用。具体的需求就是给定一个图和一个点, 求出从该点出发到各个点的最短距离。下边放一张从wiki拿来的图: 不过这张是无向图, 但是大致的流程是类似的。 下面通过一个更具体是示例来说明, 我们的图如下所示: 需求: 从1开始, 到各个点的最短距离准备: 我们可以利用三个数组存储相关的信息 sign[] 记录已经被访问过的点 shortest[] 保存当前点到1的最短距离 precursor[] 记录1到当前点的路径中, 当前点的前驱点 初始化:根据图将三个数组分别初始化为, 规定-1为无穷远sign[] 1, 0, 0, 0, 0shortest[] -1, 3, -1, -1, 30precursor[] 1, 1, 1, 1, 1 过程: 找到距离1最短的点, 一看是2, 距离为3, 把2标记为访问过的, 更新sign数组; 然后从2找没标记过的点x, 看2到x的距离加上0到2的距离是否小于0到x的距离, 如果小于的话, 就更新shortest数组; 把x的前缀改为2, 更新precursor数组。 经过这些操作后, 三个数组变成这样了: sign[] 1, 1, 0, 0, 0shortest[] -1, 3, 28, 11, 30precursor[] 1, 1, 2, 2, 1 接下来最短距离是11, 为4, 再从4开始重复上述步骤: sign[] 1, 1, 0, 1, 0shortest[] -1, 3, 15, 11, 23precursor[] 1, 1, 4, 2, 4 直到所有的点都标记为访问过的, 最终结果为: sign[] 1, 1, 1, 1, 1shortest[] -1, 3, 15, 11, 23precursor[] 1, 1, 4, 2, 4 根据这些记录我们可以得出1到各个点的最短距离以及路径:1-&gt;2 3 1-&gt;21-&gt;3 15 1-&gt;2-&gt;4-&gt;31-&gt;4 11 1-&gt;2-&gt;41-&gt;5 23 1-&gt;2-&gt;4-&gt;5 这里说一下路径的计算过程, 以1-&gt;3为例, 根据precursor记录的前驱, 我们看到3的前驱是precursor[3]=4, 即4-&gt;3, 4的前驱precursor[4]=2, 即2-&gt;4-&gt;3, 再看2的前驱precursor[2]=1, 即1-&gt;2-&gt;4-&gt;3, 这样就求出了完整的路径。 下面贴份code, 写的不好看请原谅- -: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package graph;import java.util.Scanner;/** * Dijstra 算法 有向图，有权值，求一个点到各个点的最短距离 * */public class Dijkstra &#123; private static Scanner s = new Scanner(System.in); /** * 输入图 * @param n 点的个数 * @param k 边的个数 * @param a 保存图的信息 */ private static void input(int n, int k, int[][] a) &#123; for (int i = 0; i &lt; n; i ++) &#123; for (int j = 0; j &lt; n; j ++) &#123; // 初始化 a[i][j] = -1; &#125; &#125; for (int i = 0; i &lt; k; i ++) &#123; int start = s.nextInt(); int end = s.nextInt(); int value = s.nextInt(); a[start][end] = value; &#125; &#125; private static void printEdges(int[][] a) &#123; for (int i = 0; i &lt; a.length; i ++) &#123; for (int j = 0; j &lt; a.length; j ++) &#123; System.out.print(a[i][j] + " "); &#125; System.out.println(); &#125; &#125; /** * 基本思路: * 1. 从0开始, 找到最短的一条边, 假设为k点, 即0-k最短 * 2. 从k点开始, 找k到各个点的距离, 如果比0到它更短, 则更新最短距离, 并且更新前驱节点 * * @param a 图 */ private static void doDijkstra(int[][] a) &#123; int len = a.length; // 标记已经访问过的点 int[] sign = new int[len]; // 存放当前0到个点的最短距离 int[] shortest = new int[len]; // 存放当前节点的前驱 int[] precursor = new int[len]; // 循环次数? int count = len - 1; // 初始化最短距离 System.arraycopy(a[0], 0, shortest, 0, len); // 0开始的, 所以0默认已经访问过了 sign[0] = 1; while (count &gt; 0) &#123; int min = 0x7fffffff; int pos = -1; // 从shortest中找到没标记过的点, 且距离最小的 for (int i = 0; i &lt; len; i ++) &#123; if (sign[i] == 0) &#123; if (shortest[i] &gt; 0 &amp;&amp; shortest[i] &lt; min) &#123; min = shortest[i]; pos = i; &#125; &#125; &#125; // 标记访问 sign[pos] = 1; // 修改最短路径 for (int i = 0; i &lt; len; i ++) &#123; if (a[pos][i] &gt; 0 &amp;&amp; sign[i] == 0) &#123; // -1标识无穷远, 能到达肯定比无穷远要好 if (shortest[i] == -1 || a[pos][i] + shortest[pos] &lt; shortest[i]) &#123; shortest[i] = a[pos][i] + shortest[pos]; // 修改前驱 precursor[i] = pos; &#125; &#125; &#125; count --; &#125; System.out.println("shortest: "); for (int i = 1; i &lt; len; i ++) &#123; System.out.println(0 + "-&gt;" + i); System.out.print(0 + " "); dfs(precursor, i); System.out.println(); &#125; &#125; /** * 递归输出, 为了从头输出, 好看一点 * @param a * @param end */ private static void dfs(int[] a, int end) &#123; if (end != 0) &#123; dfs(a, a[end]); System.out.print(end + " "); &#125; &#125; public static void main(String[] args) &#123; int n = s.nextInt(); int k = s.nextInt(); int[][] edges = new int[n][n]; // 输入 Dijkstra.input(n, k, edges); // 打印图 //Dijkstra.printEdges(edges); // 计算过程 doDijkstra(edges); &#125;&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比synchronized高级的同步结构]]></title>
    <url>%2F2018%2F09%2F07%2F%E6%AF%94synchronized%E9%AB%98%E7%BA%A7%E7%9A%84%E5%90%8C%E6%AD%A5%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[这些同步结构都在java.util.concurrent并发包下，这里只看一下基础的用法。 CountDownLatch直接用API来介绍吧 A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.简单说来就是让一些线程等待其他线程的操作完成 写一个示例程序: 12345678910111213141516171819202122232425262728293031323334353637383940package concurrent.countdownlatch;import java.util.concurrent.CountDownLatch;public class Test1 &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(5); // 这里一般对应的操作数，这是几，就要有几次countDown操作 for (int i = 0; i &lt; 5; i ++) &#123; // 新建5个线程跑起来 MyThread myThread = new MyThread(i, countDownLatch); myThread.start(); &#125; System.out.println("prepare to wait for other thread finish work..."); countDownLatch.await(); // 要点1 System.out.println("all threads have finish work!!!"); &#125;&#125;class MyThread extends Thread &#123; private int tId; private CountDownLatch countDownLatch; public MyThread(int tId, CountDownLatch countDownLatch) &#123; this.tId = tId; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; try &#123; // Thread.sleep(1000 * (5-tId)); // 模拟工作, 不要介意为啥这样写 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("thread i=" + tId + " has finish work"); countDownLatch.countDown(); // 要点2 &#125;&#125; 附上运行结果: 注意我注释中标记了要点的地方，CountDownLatch主要操作方式就是await/countDown，在该程序中，await在main方法中执行，从线程方面来看，就是我们的main线程在等待5个MyThread线程执行结束，就是这样 CyclicBarrier再来看看API中的第一句 A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.允许一堆线程在barrier互相等待 看个示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package concurrent.cyclicbarrier;import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;public class Test2 &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(5, ()-&gt;&#123; // 要点1 System.out.println("all thread arrive barrier !! "); System.out.println("let's rest a while"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); for(int j = 0; j &lt; 5; j ++) &#123; Mythread mythread = new Mythread(cyclicBarrier, j); mythread.start(); &#125; &#125;&#125;class Mythread extends Thread &#123; private CyclicBarrier cyclicBarrier; private int j; // 休息时间 public Mythread(CyclicBarrier cyclicBarrier, int j) &#123; this.cyclicBarrier = cyclicBarrier; this.j = j; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 3; i ++) &#123; try &#123; Thread.sleep(j*1000); // 模拟工作 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + " run i=" + i); try &#123; cyclicBarrier.await(); // 要点2 &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行结果: 先说一下要点1，在创建CyclicBarrier对象时可以传递一个Runnable对象，这个Runnable会在所有的相互等待的线程都到达barrier时执行，从运行结果可以看出来，当我们的5个线程都做完了工作执行await之后，Runnable定义的操作就会运行。 区别这里简单写一下二者的区别 CountDownLatch是一次性的, 因为初始化中传递的count在CountDownLatch中是无法被恢复的; 但是CyclicBarrier是可以用多次的，从运行结果我们也可以看出来, 这是因为CyclicBarrier内部把最初的值保留在parties中, 每次执行减法的是它的拷贝count, 当CyclicBarrier运行完一轮后, 通常会自动调用nextGeneration方法, 在该方法内部又把parties赋值给count了 逻辑上来讲, CountDownLatch是让A组线程等待B组线程全部执行完, 然后A组线程继续做该做的; CyclicBarrier是A组线程中的每个线程都做一些事到达barrier, 即进入等待状态后, CyclicBarrier可以做个总结之类的, 然后A组线程中的每一个又开始继续做事, 这样循环下去]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>CountDownLatch</tag>
        <tag>CyclicBarrier</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap与Hashtable的异同点]]></title>
    <url>%2F2018%2F08%2F23%2FHashMap%E4%B8%8EHashtable%E7%9A%84%E5%BC%82%E5%90%8C%E7%82%B9%2F</url>
    <content type="text"><![CDATA[总结一下HashMap和Hashtable的区别，可能会不全，后面有发现了再补充。 并发这应该是最明显的一点不同了，HashMap不是线程安全的，但是Hashtable是的，看一下Hashtable中的方法，基本上都加了synchronized，但是呢，这种同步实在是太粗糙了，所以在并发的情况下才会推荐使用ConcurrentHashMap吧。 构造方式默认容量在构建相应的实例时，如果没有指定initialCapacity，HashMap默认指定为16，Hashtable默认指定为11： 123456789101112//Hashtable默认构造函数public Hashtable() &#123; this(11, 0.75f);&#125;/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 创建桶他们两个实际创建桶的时机也是不一样的，HashMap应该是懒加载： 1234567891011121314151617181920212223242526272829303132333435363738public Hashtable(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal Load: "+loadFactor); if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry&lt;?,?&gt;[initialCapacity]; // 在这里就为桶分配内存了 threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);&#125;//但是在HashMap的构造函数中，找不到类似的为桶分配内存的命令，//因为在分配内存是在resize()方法中，这里截取部分Node&lt;K,V&gt;[] oldTab = table;int oldCap = (oldTab == null) ? 0 : oldTab.length; // 由于没有分配内存，所以此时table还是null，因此oldCap == 0int oldThr = threshold;int newCap, newThr = 0;if (oldCap &gt; 0) &#123; // ...&#125;else if (oldThr &gt; 0) // 注意如果新建HashMap时指定了initialCapacity，那么会根据这个值初始化 threshold newCap = oldThr;else &#123; // 这里就是啥都没指定的 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);&#125;if (newThr == 0) &#123; // 确定新阀值 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);&#125;threshold = newThr;@SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 呐呐，在这分配内存table = newTab; // 我们的table不为null了 hashHashtable计算元素的hash值是这样的： 12int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length; 而HashMap就比较精致了： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 一个是求余，一个是位运算，效率肯定也不一样。 结构虽然从整体上来看，HashMap和Hashtable都是用链地址法解决冲突，但是1.8的HashMap作了优化，当冲突超过一定时，会将链表进行树化。 扩容两个数据结构扩容的方式也不同，Hashtable就比较简单了，扩大容量后，把旧table中的点遍历一遍，重新计算hash值采用头插法放到新table中；而HashMap就不一样了，除了要考虑树的情况，在从旧table放到新table的过程中，是先把旧table中的冲突链表或树，分成两份，放进新table中(具体的可以看这：https://zero22.top/2018/08/17/HashMap-%E4%B8%80/)。 总结对比一下HashMap和Hashtable，不得不佩服Josh Bloch、Arthur van Hoff、Neal Gafter、Doug Lea等作者，总是在不断的优化、创新，让我看到这么漂亮的code，感谢。 - -]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>different</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashtable]]></title>
    <url>%2F2018%2F08%2F22%2FHashtable%2F</url>
    <content type="text"><![CDATA[基本上不会用到了，在官方API中这样写道： Unlike the new collection implementations, Hashtable is synchronized. If a thread-safe implementation is not needed, it is recommended to use HashMap in place of Hashtable. If a thread-safe highly-concurrent implementation is desired, then it is recommended to use ConcurrentHashMap in place of Hashtable. 如果必须需要线程安全，请用HashMap；如果高并发线程安全是必要的，请用ConcurrentHashMap。不过还是来了解一下吧，看看Hashtable为啥被抛弃了。 put1234567891011121314151617181920212223public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; // Makes sure the key is not already in the hashtable. Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings("unchecked") Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; for(; entry != null ; entry = entry.next) &#123; if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; entry.value = value; return old; &#125; &#125; addEntry(hash, key, value, index); return null;&#125; 从put中我们可以知道下面几点： value不能为null，其实key也不能为null； 索引的计算方法 (hash &amp; 0x7FFFFFFF) % tab.length ，这个叫做除留余数法，用到了取模，可能会影响效率。 当产生冲突时，用链地址法解决冲突，并且采用头插法把新来的插在首位。 当经过上面的步骤还没有处理新来的key-value，就交给addEntry 12345678910111213141516171819private void addEntry(int hash, K key, V value, int index) &#123; modCount++; Entry&lt;?,?&gt; tab[] = table; if (count &gt;= threshold) &#123; // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); index = (hash &amp; 0x7FFFFFFF) % tab.length; &#125; // Creates the new entry. @SuppressWarnings("unchecked") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++;&#125; 这个modCount后面再说 首先判断hashtable中的键值对的数量是否超过了阀值，超过了要先扩容再重新计算index，否则直接插入。要注意的是这种情况，在put的过程中，hash冲突了，但是key值不一样，这时候也还是要到addEntry中，但是我们看好像并没有把这个新的key-value插入到链表呀，但其实看看这个new Entry&lt;&gt;(hash, key, value, e) 就会发现key-value是在这个时候被放到e的前边了，还是头插法。 再来继续看rehash 1234567891011121314151617181920212223242526272829protected void rehash() &#123; int oldCapacity = table.length; Entry&lt;?,?&gt;[] oldMap = table; // overflow-conscious code int newCapacity = (oldCapacity &lt;&lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) &#123; if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE; &#125; Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; modCount++; threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; for (int i = oldCapacity ; i-- &gt; 0 ;) &#123; for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) &#123; Entry&lt;K,V&gt; e = old; old = old.next; int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; &#125; &#125;&#125; 逻辑比较简单： 1.容量扩大一倍加一，最多能有0x7fffffff-8个桶 2.按照新容量重建一个hashtable 3.计算阀值 4.把旧table中的点按照新table的长度重新计算索引，放到新table中，采用头插法 get很简单，就看看 1234567891011public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return (V)e.value; &#125; &#125; return null;&#125; contains123456789101112131415161718192021222324252627282930313233//这个其实就是判断是否包含某个value，看下边的containsValue就知道//判断包含value比判断包含key的代价更高，因为直接判断包含value需要遍历整个hashtablepublic synchronized boolean contains(Object value) &#123; if (value == null) &#123; throw new NullPointerException(); &#125; Entry&lt;?,?&gt; tab[] = table; for (int i = tab.length ; i-- &gt; 0 ;) &#123; for (Entry&lt;?,?&gt; e = tab[i] ; e != null ; e = e.next) &#123; if (e.value.equals(value)) &#123; return true; &#125; &#125; &#125; return false;&#125;public boolean containsValue(Object value) &#123; return contains(value);&#125;public synchronized boolean containsKey(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return true; &#125; &#125; return false;&#125; forEach1234567891011121314151617public synchronized void forEach(BiConsumer&lt;? super K, ? super V&gt; action) &#123; Objects.requireNonNull(action); // explicit check required in case // table is empty. final int expectedModCount = modCount; Entry&lt;?, ?&gt;[] tab = table; for (Entry&lt;?, ?&gt; entry : tab) &#123; while (entry != null) &#123; action.accept((K)entry.key, (V)entry.value); entry = entry.next; if (expectedModCount != modCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; 这个方法是jdk1.8新增的，支持lambda表达式，下次要遍历时可以.一下看看有没有forEach， 有的话就可以这样遍历了： 123456789101112131415161718Hashtable&lt;Integer, String&gt; hashtable = new Hashtable&lt;&gt;();hashtable.put(1, "one");hashtable.put(0, "two");hashtable.put(5, "five");hashtable.put(2, "two");hashtable.put(100, "hundred");hashtable.put(55, "fifty five");hashtable.forEach((key, value) -&gt; System.out.println("key: " + key + " value: " + value));//output----------------------------------------------key: 55 value: fifty fivekey: 0 value: twokey: 100 value: hundredkey: 1 value: onekey: 2 value: twokey: 5 value: five otherfail-fast上面看到了一个变量，叫做modCount，我理解为修改次数，在绝大多数集合或Map中都能看到这个值(至于是不是绝大多数我也不太确定，后面看的多了在作修改)，看一下官方对这个值的解释： The number of times this Hashtable has been structurally modifiedStructural modifications are those that change the number of entries inthe Hashtable or otherwise modify its internal structure (e.g.,rehash). This field is used to make iterators on Collection-views ofthe Hashtable fail-fast. (See ConcurrentModificationException). 大概就是当Hashtable发生结构变化(比如增删entry、rehash等)时，这个值就会自加一表示Hashtable被修改了。这个值主要用于iterator的fail-fast机制，对于该机制Hashtable也作了解释： if the Hashtable is structurally modified at any timeafter the iterator is created, in any way except through the iterator’s ownremove method, the iterator will throw a ConcurrentModificationException. 当迭代器创建后，任何非迭代器产生的结构变化都会抛出ConcurrentModificationException异常，再找找具体的使用吧： 123456789101112131415161718public synchronized void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Objects.requireNonNull(function); // explicit check required in case // table is empty. final int expectedModCount = modCount; Entry&lt;K, V&gt;[] tab = (Entry&lt;K, V&gt;[])table; for (Entry&lt;K, V&gt; entry : tab) &#123; while (entry != null) &#123; entry.value = Objects.requireNonNull( function.apply(entry.key, entry.value)); entry = entry.next; if (expectedModCount != modCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; 其实上边的forEach也有用到，来分析一下： 首先在任何操作之前，记录此时的modCount值 遍历hashtable进行替换操作 每当替换一个entry.value后，都要比较现在的modCount和刚在记录的expectedModCount是否一致，如果不一致就会抛出异常。 看起来似乎可以保证并发安全? 不！再来看看官方说明： Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification.the fail-fast behavior of iterators should be used only to detect bugs. fail-fast机制只用来检测程序bug！ fail-safe参考这里除了fail-fast，还有另一种机制fail-safe，简单说来就是： 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>fail-fast</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次WEB请求全过程]]></title>
    <url>%2F2018%2F08%2F21%2F%E4%B8%80%E6%AC%A1WEB%E8%AF%B7%E6%B1%82%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[输入URL首先，用户在Web浏览器（如IE）地址栏输入URL，比如：https://zero22.top 前面的https是协议类型，后面的zero22.top指定被访问的服务器的域名，没有加冒号和端口号表示访问的是默认的端口号80。 DNS解析由于所发出的数据要通过被访问主机的IP地址进行传输和路由，所以要先通过DNS服务器将域名解析为IP地址： 主机产生一个DNS请求，传递给传输层，通过UDP产生一个UDP报文；再传递给网络层产生一个IP报文，目的地址是DNS服务器的IP地址；在数据链路层通过ARP协议得到到达DNS服务器的下一跳的MAC地址；把数据帧通过以太网传输给DNS服务器。 DNS服务器将收到的帧向上传给传输层，得到UDP报文。通过UDP报文中指定的端口号传给DNS应用程序。这里，由于是内网域名和内网DNS服务器，DNS服务器中有相应的表项，如果不在当地，本地DNS服务器还要向上级的DNS服务器发出DNS查询请求，如此递归直到查到要解析的域名的IP地址。 DNS把通过DNS应答将得到的IP地址返回给请求的主机。 HTTP嘶挞哆现在，浏览器得到对方的IP地址了，即进入HTTP流程。HTTP的工作流程分为以下四步： 通过三次握手建立TCP连接。 客户端发送请求给服务器。 服务器收到请求后，给予相应的响应消息，并传输相应的响应数据给客户端。 客户端接收完服务器返回的信息后，与服务器断开连接。 THREE-WAY HANDSHAKE用Wireshark来看看三次握手： 首先我给服务器发送一个TCP报文：随后服务器端回我一个：最后我再给服务器发一个：由上边可以知道，客户端和服务器端发送的Sequence number是没有关系的，各自算各自的。 至于建立连接之后，客户端与服务器端数据的传送，现在不想看了，大概根据对方的ip和mac地址，传到相应的主机？解析后主机在给相应的应用程序？不很清楚，再看吧 - -]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>three-way handshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NavigableMap/NavigableSet]]></title>
    <url>%2F2018%2F08%2F21%2FNavigableSet-NavigableMap%E5%8F%8ASortedSet-SortedMap%2F</url>
    <content type="text"><![CDATA[navigation英 [ˌnævɪˈgeɪʃn] 美[ˌnævɪˈɡeʃən]noun[U]导航；领航the skill or the process of planning a route for a ship or other vehicle and taking it there 前边大概看了 TreeMap和TreeSet，更多的细节今后有需求在研究吧，再来看看他们分别实现的接口NavigableSet/NavigableMap，他们分别继承了SortedSet/SortedMap。 NavigableMap其中主要的方法都和其名称相符，即导航，查找和指定目标最接近的值，或是大于，或是小于；主要分为两类，找key或者找Entry： 123//返回key值大于或等于指定key的Entry或KeyMap.Entry&lt;K,V&gt; ceilingEntry(K key);K ceilingKey(K key); 123//小于等于的Map.Entry&lt;K,V&gt; floorEntry(K key);K floorKey(K key); 12345//不包括等于Map.Entry&lt;K,V&gt; lowerEntry(K key);K lowerKey(K key);Map.Entry&lt;K,V&gt; higherEntry(K key);K higherKey(K key); 12NavigableSet&lt;K&gt; descendingKeySet();NavigableMap&lt;K,V&gt; descendingMap(); 返回按照key值降序的集合；返回的集合和原集合是相互联系的(The descending map is backed by this map)，修改任一集合都会对另外一个集合产生影响；用迭代器遍历集合的同时修改集合，那么遍历的结果是不确定的。下面写几个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public void testDesc() &#123; NavigableMap&lt;Integer, String&gt; map = new TreeMap&lt;&gt;(); map.put(1,"one"); map.put(-1, "negative one"); map.put(56, "fifty six"); map.put(9, "nine"); map.put(0, "zero"); map.put(20, "twenty"); System.out.println("before desc---------------------"); for (Map.Entry&lt;Integer,String&gt; ele: map.entrySet() ) &#123; System.out.println(ele.getKey() + " " + ele.getValue()); &#125; NavigableMap&lt;Integer, String&gt; descMap = map.descendingMap(); System.out.println("after desc-----------------------"); for (Map.Entry&lt;Integer,String&gt; ele: descMap.entrySet() ) &#123; System.out.println(ele.getKey() + " " + ele.getValue()); &#125; descMap.put(100, "one hundred"); System.out.println("after desc put-------------------"); for (Map.Entry&lt;Integer,String&gt; ele: map.entrySet() ) &#123; System.out.println(ele.getKey() + " " + ele.getValue()); &#125;&#125;result：before desc----------------------1 negative one0 zero1 one9 nine20 twenty56 fifty sixafter desc-----------------------56 fifty six20 twenty9 nine1 one0 zero-1 negative oneafter desc put--------------------1 negative one0 zero1 one9 nine20 twenty56 fifty six100 one hundred 当我在逆序集合中插入新Entry后，在遍历原来的map也打印了新加入的Entry，所以是相互影响的。 1234//返回key值小于toKey的Entry组成的Map，也是相互关联的，需要注意的是，在headMap中新增Entry时，新Entry的key值同样不能大于toKey，否则会抛出异常；inclusive用来表示是否包括toKeyNavigableMap&lt;K,V&gt; headMap(K toKey, boolean inclusive);//对应于headMap，返回大于fromKey的NavigableMap&lt;K,V&gt; tailMap(K fromKey, boolean inclusive); 突然感觉没有写的必要？ NavigableSetset中的操作基本上就是map中对于key的操作，下面放一些方法： 1234567E lower(E e);E floor(E e);E ceiling(E e);E higher(E e);NavigableSet&lt;E&gt; descendingSet();NavigableSet&lt;E&gt; headSet(E toElement, boolean inclusive);NavigableSet&lt;E&gt; tailSet(E fromElement, boolean inclusive); 唯一有点区别的就是Set中多了迭代器iterator，毕竟Collection继承了Iterator 12Iterator&lt;E&gt; iterator();Iterator&lt;E&gt; descendingIterator(); 至于他们的父类Sorted一族也是接口，没什么好看的。在jdk1.8中，为集合新增了Spliterator(并行迭代器?)这个玩意，后边再看吧 - -]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TreeMap与TreeSet]]></title>
    <url>%2F2018%2F08%2F20%2FTreeMap%2F</url>
    <content type="text"><![CDATA[我们知道，map中的元素是由键值对组成的，TreeMap就是把这些键值对通过某个因素连接组成树的一种数据结构。其中TreeMap中的树是红黑树，在构造TreeMap对象时，可以选择传入一个比较器Comparator，如果没传的话，那么TreeMap中元素的key需要实现Comparable接口，这个规定是强制的，不然会有异常。下面看看常用的方法，说是常用我却没用过，还有一个TreeSet，放一起看看。jdk1.8版本的。 TreeMapput12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); size++; modCount++; return null;&#125; 不是很难，如果树为空，就新建root；否则根据Comparator/Comparable比较key值，如果key值已经存在了，直接用新value覆盖之；不然就找到插入点进行插入，最后作调整。TreeMap的作者也参与了HashMap的编写，但是其中红黑树调整的写法却不一样。 getEntry这里就写个最简单的get方法吧，里边还有各种get方法，比如模糊查找，找比特定值大的部分中的最小的，或者比特定值小的部分中最大的等等， 1234567891011121314151617181920final Entry&lt;K,V&gt; getEntry(Object key) &#123; // Offload comparator-based version for sake of performance if (comparator != null) return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125; 按照Comparator或者Comparable来查找指定的key。 successor个人认为这个方法也挺重要的，不过一般我们不用，他为TreeMap中其他方法提供，用来返回特定Entry的后继节点，即比他大的且最靠近他的 123456789101112131415161718static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; else if (t.right != null) &#123; Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; &#125; else &#123; Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125;&#125; 比指定Entry大的值出现在两个地方，Entry的右孩子或者Entry所在的子树为另一子树的左孩子。 TreeSet什么都不说，让我们看看TreeSet的构造函数吧： 123456789101112131415public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;());&#125;public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; this(new TreeMap&lt;&gt;(comparator));&#125;TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m;&#125;//以及一些成员变量private transient NavigableMap&lt;E,Object&gt; m;private static final Object PRESENT = new Object(); 原来TreeSet就是把TreeMap包装一下? 你是对的 再来看看他的一些方法 123public boolean add(E e) &#123; return m.put(e, PRESENT)==null;&#125; // 哈哈，Entry不够，Object来凑 其他的方法就是 NavigableSet接口中的方法了，主要是给定搜索目标报告最接近匹配项的导航方法，比如： 123public E ceiling(E e) &#123; return m.ceilingKey(e);&#125; 等都是调用TreeMap中关于key的操作。 over]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HashMap(二)]]></title>
    <url>%2F2018%2F08%2F20%2FHashMap-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[jdk1.8中的HashMap额外引用了红黑树，当冲突链表太长的话，就会把链表转化为红黑树的结构，避免了原来的当冲突太多了，查找效率可能会退化到O(n)的情况。红黑树在HashMap中表现为TreeNode，下面看一下主要的方法。 treeify具体的树化过程，但是里边有个地方我不是太明白： 1234567891011121314151617181920212223for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; root = balanceInsertion(root, x); break; &#125;&#125; 上边是查找插入点的过程，这个h是链表中待插入的点的hash值，ph是树中的点的hash值，话说为什么要先比较这俩呢，既然在一条冲突链表里，hash值还能不一样吗?所以一般情况下，插入树中主要比较的是他们的key值，如果key值也一样就比较两个节点的原始hashcode，原始hashcode也相等被包含在-1中。 untreeify解除树化，树中节点数小于等于6，就会转化为链表。主要操作就是把链表中的TreeNode变成Node。链表中的点称为 Node，红黑树中的点称为 TreeNode，这个TreeNode最终还是继承的该Node，链表主要用pre、next等，树主要用left、right、parent等，所以这两种点可以相互转化。 split只在resize时使用，首先根据next、pre把树分成lo和hi两条链表，放到新table中，如果长度大于6再树化。 红黑树红黑树的规则： 根节点是黑的 叶子是黑的 树中的节点是黑或红 红色节点的孩子是黑的 从任一节点开始到能到的叶子，经过的黑色节点数目是一样的 具体看wiki 其他关于HashMap其他的我认为没什么好看的了，最后把get也一起放这就结束吧。 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 在经过了put之后，我感觉get就没啥好说的，找到索引位置，从第一个开始往后找，如果是树的话就用红黑树的找法。 over.]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HashMap(一)]]></title>
    <url>%2F2018%2F08%2F17%2FHashMap-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[打算看看关于Collection/Map的源码，先拿HashMap试试手吧，这一篇主要看看HashMap的put方法，把与其相关的方法都揪出来。注意，源码是jdk1.8版本的 put123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 这里有个计算key的hash值得方法， hash1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这个方法简单说来就是，为了尽量减少冲突，并且还要考虑效率，在计算key的hash值时，也让hashCode的高位参与运算。 putVal123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 哇，怎么这么长，别着急，我们慢慢看，后边还有更长的呢。 首先，如果当前的”篮子”为空或者长度为0，那么很明显需要初始化，用到了resize() ； 接下来，我们可以看到索引值得计算方法： (n-1) &amp; hash其中n为table的长度，都是2次幂，那么n-1 就是这样的了： 11…111hash为前面计算的高位和低位都参与的hash值从这里可以看出来，table的索引值是依靠hash值得低几位决定的。如果当前索引没被占过，那么新Node直接放这就完事了。 下边就是更新值的操作了如果老点的hash值和key值和新点相同，记录老点；如果老点所在的”篮子”后边跟的太多了，导致变异成了树，把新点放到树里边putTreeVal(this, tab, hash, key, value) ，记录返回值；最后来个循环，在”篮子”后边的链表中继续找，没找到就把新点加在链表的最后，注意，加完了要判断链表的长度是否大于树化的临界值8，可能要进行树化 treeifyBin(tab, hash) ；上面三种可能都记录了老点，但是putTreeVal()目前不知道返回什么，先不管了，老点都被e记录了，如果e不为空，说明新点和老点重复了，要进行覆盖，最后返回老点的值， 如果没有更新值，说明新点被添加到table中了，接下来要判断table的大小有没有超过阀值，如果超过阀值又要resize()，最后返回null。 下面再来看看putVal中涉及到的各种方法： resize初始化table或者table容器超过阀值都要进行resize 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 先把table的长度、阀值什么的确定下来 如果老table存在，即其长度大于0，如果长度大于2^30，那就不用重建了，因为长度已经是最大值了，把阀值调到Integer.MAX_VALUE；否则，老table长度扩大一倍，阀值也扩大一倍； 老table长度为0，新table长度为阀值； 如果老table长度为0，并且老阀值不大于0，那就按默认的来，长度16，阀值12 下边就是把老table中的点放到新table中的过程了 循环遍历每个老点 如果该点没有冲突，直接放新table中； 如果该点后面跟着树，那么((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap) 否则该点后边就是不算长的冲突链表了； 创建两个链表，用来减少冲突，遍历链表时，划分某一点的依据是 (e.hash &amp; oldCap) == 0，由于table的长度都是2的次幂，比如长度为16时，oldCap为00010000，产生冲突的点中，其hash值的低四位是一样的，比如这两个：e1.hash=11010101，e2.hash=10100101，他们最后四位是一样的，但是oldCap位就说不准了，比如e1是1，e2是0，这样他们就被放到不同的链表 loHead、hiHead中了。所以老table中的一条冲突链表到新table中变成两条冲突链表了； 最后是两个新冲突链表在新表中的位置，一个不变，一个在原位的基础上位移老table长度的距离。 关于和树相关的操作，等我把红黑树那个了再说吧- -]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java中的Enum]]></title>
    <url>%2F2018%2F08%2F16%2Fjava%E4%B8%AD%E7%9A%84Enum%2F</url>
    <content type="text"><![CDATA[最近看java内存模型讲 volatile时候，举了一个DCL(Double Check Lock?)双重检测的单例模式，让我想到了之前看过的枚举实现单例模式，感觉很神奇而且陌生，讲道理，我基本上没怎么用过枚举，还是我见识太少了吧，所以我打算看看这个Enum是怎么回事。 初识一般用枚举的话，我们一般用的是 “enum”，而不是”Enum”，就好比 “class” 和 “Class”一样。枚举是一种特殊的类，声明时用”enum”，就像接口用”interface”一样，写个简单的例子: 123456789101112public enum EnumTest&#123; ENUM1; EnumTest()&#123; System.out.println("this is EnumTest()"); &#125; private void nothing() &#123; System.out.println("nothing"); &#125; public static void main(String[] args)&#123; EnumTest.ENUM1.nothing(); &#125;&#125; 看起来和一个类没什么区别，可以有 成员变量、方法什么的，但是这也只是看起来而已。 深入下面我们更加深入的看一看这个enum到底是什么玩意，直接反编译： 1234567891011121314151617181920212223242526272829303132333435363738394041public final class EnumTest extends java.lang.Enum&lt;EnumTest&gt; &#123; public static final EnumTest ENUM1; public static EnumTest[] values(); Code: 0: getstatic #1 // Field $VALUES:[LEnumTest; 3: invokevirtual #2 // Method "[LEnumTest;".clone:()Ljava/lang/Object; 6: checkcast #3 // class "[LEnumTest;" 9: areturn public static EnumTest valueOf(java.lang.String); Code: 0: ldc #4 // class EnumTest 2: aload_0 3: invokestatic #5 // Method java/lang/Enum.valueOf:(Ljava/lang/Class;Ljava/lang/String;)Ljava/lang/Enum; 6: checkcast #4 // class EnumTest 9: areturn public static void main(java.lang.String[]); Code: 0: getstatic #11 // Field ENUM1:LEnumTest; 3: invokespecial #12 // Method nothing:()V 6: return static &#123;&#125;; Code: 0: new #4 // class EnumTest 3: dup 4: ldc #13 // String ENUM1 6: iconst_0 7: invokespecial #14 // Method "&lt;init&gt;":(Ljava/lang/String;I)V 10: putstatic #11 // Field ENUM1:LEnumTest; 13: iconst_1 14: anewarray #4 // class EnumTest 17: dup 18: iconst_0 19: getstatic #11 // Field ENUM1:LEnumTest; 22: aastore 23: putstatic #1 // Field $VALUES:[LEnumTest; 26: return&#125; 哇，可以看到我之前在枚举类中加入的 “ENUM1”竟然是这个类的静态实例，而且还是final的，那么这里有个问题，final变量在使用之前必须初始化，但是我们看到这里只是声明，并没有初始化。我们继续往下看，发现还有一个静态代码块！这一下应该能猜到ENUM1是在静态代码块里初始化的，我们来看看。 new 在java堆上为EnumTest对象分配内存空间，并将地址压入操作数栈顶 dup 复制操作数栈顶值，并将其压入栈顶，也就是说此时操作数栈上有连续相同的两个对象地址 ldc 把常量池中 ENUM1 推送至栈顶 invokespecial 指令调用实例初始化方法”\“:(Ljava/lang/String;I)V 看到这大概也就清楚了，静态代码块中确实会初始化ENUM1，这也解决了我的一个疑惑，看下面的程序： 12345678910public enum EnumOut&#123; ONE,TWO; EnumOut()&#123; System.out.println("this is constructor"); &#125; public static void main(String[] args)&#123; System.out.println("this is main"); &#125;&#125; 直接给出输出： 123this is constructorthis is constructorthis is main 在没有分析字节码之前，我不懂为什么会执行构造函数，但现在，豁然开朗。另外，要注意enum的构造方法只能是private的。 实现单例模式下面看看如何使用枚举实现单例模式： 12345678910111213141516171819202122public enum SingletonEnum&#123; INSTANCE; private Singleton instance; private SingletonEnum() &#123; instance = new Singleton(); &#125; public Singleton getInstance()&#123; return instance; &#125; public static void main(String[] args)&#123; Singleton single1 = SingletonEnum.INSTANCE.getInstance(); Singleton single2 = SingletonEnum.INSTANCE.getInstance(); System.out.println(single1 == single2); &#125;&#125;class Singleton&#123; private int id;&#125; 在jvm第一次加载SingletonEnum类时，INSTANCE就已经被定死了，后边调用SingletonEnum.INSTANCE.getInstance() 方法时得到的都是INSTANCE对象中的Singleton，所以保证了单例。]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Leetcode 5. Longest Palindromic Substring]]></title>
    <url>%2F2018%2F08%2F14%2FManacher%E7%AE%97%E6%B3%95%E6%B1%82%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[给你一个字符串，找到一个最长的回文子串，例如，”banana”字符串的最长回文子串为”anana”，这里说的找到一个是因为一个字符串可能有多个长度相同的回文子串，这里只用返回一个就可以了。另外要区分一下回文子串和回文子序列，其实就是子串和子序列的区别。参考文章：Longest Palindromic Substring Part II维基百科：Longest palindromic substring 简化字符串首先，为了避免奇数和偶数长度的影响，我们在字符串中增加特殊符号’#’，这里我自己想这一题的时候也用了这个方法，这样加完特殊符号后，新的字符串总是奇数长度，然后在求回文串的时候，每个字符都可以当做中间值，比较他两边的字符是否相同即可。“ababa” –&gt; “#a#b#a#b#a#” 找规律在我的感觉中，算法应该就是把事物中的规律用语句表示出来，所以下面我们来看看计算最长回文子串中的规律。用一个额外的数组记录每个点为中心时的对称长度。其中C表示当前回文串的中心，L、R分别表示当前回文串的左端和右端，i为待求，i’为i关于C的对称索引，现在让你求以i为中心的回文串的最大长度，你会怎么求。我们看到，以C为中心，他两边不超过L/R的字符串都是对称的，所以我们可以直接确定P[i] = p[i’]，这样就省了一部分求P的时间。我自己做的没有用到以求的数据，每个地方都是比较他两边的字符，这样显然很浪费时间，但是Manacher算法在计算回文串长度时，用到了前边的数据，这里我第一时间想到了KMP算法求子串的长度。然后我们继续：当i=15时，能直接说P[15] = P[7] 吗，你要知道，我们前边能直接根据镜像求P有个条件，那就是我们的镜像的边界都没超过L/R，也就是能确保C两边的字符串是一模一样的，但是这里，P[7] = 7，超过了边界L，再看一张图绿色实线表示左右两边一定相同的并且P[i]一定会包含的，绿色虚线表示相同但是不一定包含在P[i]中，这里要取决于红色实线的部分，也就是说镜像得来的便利也就到R为止了，后边的就要靠自己去比较两边的字符了。总结规律： 123if P[i'] &lt; R-ithen P[i] = P[i']else P[i] &gt;= R-i 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Transform S into T.// For example, S = "abba", T = "^#a#b#b#a#$".// ^ and $ signs are sentinels appended to each end to avoid bounds checkingstring preProcess(string s) &#123; int n = s.length(); if (n == 0) return "^$"; string ret = "^"; for (int i = 0; i &lt; n; i++) ret += "#" + s.substr(i, 1); ret += "#$"; return ret;&#125;string longestPalindrome(string s) &#123; string T = preProcess(s); int n = T.length(); int *P = new int[n]; int C = 0, R = 0; for (int i = 1; i &lt; n-1; i++) &#123; int i_mirror = 2*C-i; // equals to i' = C - (i-C) P[i] = (R &gt; i) ? min(R-i, P[i_mirror]) : 0; // Attempt to expand palindrome centered at i while (T[i + 1 + P[i]] == T[i - 1 - P[i]]) P[i]++; // If palindrome centered at i expand past R, // adjust center based on expanded palindrome. if (i + P[i] &gt; R) &#123; C = i; R = i + P[i]; &#125; &#125; // Find the maximum element in P. int maxLen = 0; int centerIndex = 0; for (int i = 1; i &lt; n-1; i++) &#123; if (P[i] &gt; maxLen) &#123; maxLen = P[i]; centerIndex = i; &#125; &#125; delete[] P; return s.substr((centerIndex - 1 - maxLen)/2, maxLen);&#125;]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>Manacher</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[原子类AtomicInteger的自增]]></title>
    <url>%2F2018%2F08%2F13%2F%E5%8E%9F%E5%AD%90%E7%B1%BBAtomicInteger%E7%9A%84%E8%87%AA%E5%A2%9E%2F</url>
    <content type="text"><![CDATA[包 java.util.concurrent.atomic 下有很多原子类，可以在不使用锁的前提下实现并发，下面就AtomicInteger来深入看看原子类。 成员变量1234567891011121314private static final long serialVersionUID = 6214790243416807050L;// setup to use Unsafe.compareAndSwapInt for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; Unsafe类提供了像C/C++那样操作内存的方法，在很多地方都有用到Unsafe类。由于Unsafe类中大多都是native方法，没有提供源码，连注释都没有(jdk1.8)，看起来有点不爽。 Unsafe.objectFieldOffset()方法返回成员变量相对于对象位置的偏移量(而且这个偏移量也有点意思)，举个例子，假设Book类有个成员变量bookName，且偏移量为12，那么当新建一个Book对象，对象地址为 0x1a3234c3(这地址我瞎举的)，那么bookName的地址就是(0x1a3234c3 + 12)。该方法需要一个java.lang.reflect.Field参数，和反射有关。 value变量保存了当前的对象的值，这个变量被volatile修饰了，即当有多个线程时，只要该变量修改了，能保证其他线程在用这个值得时候是最最最新的。后边也打算写一下volatile。 重点方法12345678/** * Atomically increments by one the current value. * * @return the updated value */public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 这个方法实现了AtomicInteger的自增1操作，而且是原子的。我们知道，在多线程的环境下使用 num++，最终的结果可能会和预期有差异，这是由于num++不是原子性的，需要读取、加、写入，在这些过程中，可能会丢失掉一部分的写入操作，和数据库中的第二类丢失更新类似。那么这个方法为什么是原子性的呢? 把相关的方法都找出来: 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 很不幸的是，getAndAddInt()里边的两个方法都是native，在java中没有源码。这里我们来实际用用这些方法。 实例化UnsafeUnsafe使用了单例模式: 123456789@CallerSensitivepublic static Unsafe getUnsafe() &#123; Class var0 = Reflection.getCallerClass(); if (!VM.isSystemDomainLoader(var0.getClassLoader())) &#123; throw new SecurityException("Unsafe"); &#125; else &#123; return theUnsafe; &#125;&#125; 虽然是单例模式，但不是你想getUnsafe就能得到Unsafe的，他被设计成只有引导类加载器(bootstrap class loader)加载才能返回 Unsafe实例。 这里看文章都写了两种方法，一种是加jvm参数，另一种是反射。加jvm参数我没成功，所以说说反射吧。 123Field field = Unsafe.class.getDeclaredField("theUnsafe");field.setAccessible(true);Unsafe unsafe = (Unsafe) field.get(null); 这里有点反射的知识，当Field为成员变量时，field.get(not null)必须有个对象参数，否则会有空指针异常；如果Field是静态变量，那么就不需要对象作为参数了。 方法调用先来试试getIntVolatile方法。 1public native int getIntVolatile(Object var1, long var2); 两个参数，var1为对象，var2为变量偏移量 123456789101112class UserTwo &#123; private String name = "default"; private int userName = 12; private int fieldTwo = 2; private static String staticString = "static string";&#125;Field field1 = UserTwo.class.getDeclaredField("userName");field1.setAccessible(true);// 域偏移量long offset = unsafe.objectFieldOffset(field1);System.out.println("getInt: " + unsafe.getInt(userTwo, offset)); 上边用的getInt，和getIntVolatile大同小异，应该根据具体变量进行选择，输出结果: 1getInt: 12 所以这个方法作用为，根据变量的相对偏移量，得到具体对象的属性值 再来看看compareAndSwapInt方法 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 根据上面的分析，var1，var2用来获取对象属性值，var4为期望值，var5为目标值，写一些示例: 123456System.out.println("getAndAddInt: " + unsafe.getAndAddInt(userTwo, offset, 12));System.out.println("test=" + field1.get(userTwo));System.out.println("compareAndSwapInt: " + unsafe.compareAndSwapInt(userTwo, offset , 24, 23));System.out.println("test=" + field1.get(userTwo));System.out.println("compareAndSwapInt: " + unsafe.compareAndSwapInt(userTwo, offset , 45, 24));System.out.println("test=" + field1.get(userTwo)); 输出结果: 123456getAndAddInt: 12test=24compareAndSwapInt: truetest=23compareAndSwapInt: falsetest=23 getAndAddInt，当执行成功时，即实际属性值和期望值相同，即那段时间内内存中的值没有修改过，可以更新，则返回旧值，但其实这时实际内存中的值已经更新了，12+12，所以得到24；而 compareAndSwapInt，当执行成功时返回true，并将内存中的值更新为目标值，否则返回false。 所以，getAndAddInt方法的大致流程为，取内存中的值，把该值当做目标值，在compareAndSwapInt中在此比较内存中的值和目标值是否相同，如果相同说明其他线程没有修改该变量，此线程可以进行修改，但是具体的修改过程我就不知道，可能还需要看下C++代码吧]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>unsafe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Comparator/Comparable]]></title>
    <url>%2F2018%2F08%2F10%2FComparator-Comparable%2F</url>
    <content type="text"><![CDATA[关于java中的Comparator和Comparable，经常会看到，但是因为没有深入的研究，老是把这两个东西搞混淆，很烦，在这里总结一下。 字面意思Comparator: 比较器，就像是一个工具一样。Comparable: 可比较的，描述一个类本身的属性。 java.util.Comparator最主要的方法123456789101112/*** @param o1 the first object to be compared.* @param o2 the second object to be compared.* @return a negative integer, zero, or a positive integer as the* first argument is less than, equal to, or greater than the* second.* @throws NullPointerException if an argument is null and this* comparator does not permit null arguments* @throws ClassCastException if the arguments' types prevent them from* being compared by this comparator.*/int compare(T o1, T o2); 可以看到当有入参为null时就会抛出异常 使用 新建比较类 实现此接口，重写方法 自己调用该方法进行比较或者作为Collections.sort等入参 示例代码:结果: java.util.Comparable只有一个方法12345678910/*** @param o the object to be compared.* @return a negative integer, zero, or a positive integer as this object* is less than, equal to, or greater than the specified object.** @throws NullPointerException if the specified object is null* @throws ClassCastException if the specified object's type prevents it* from being compared to this object.*/public int compareTo(T o); 使用 实现接口，重写方法 调用该方法 示例代码:结果: 扩展java.util.Collections.sort最终还是会调用java.util.Arrays里的sort方法，我们跟着他在源码中跳几下，看看这个过程 step0 step1 step2 step3 没有比较器 介绍 /** * Sorts the specified array of objects into ascending order, according * to the {@linkplain Comparable natural ordering} of its elements. * All elements in the array must implement the {@link Comparable} * interface. Furthermore, all elements in the array must be * &lt;i&gt;mutually comparable&lt;/i&gt; (that is, {@code e1.compareTo(e2)} must * not throw a {@code ClassCastException} for any elements {@code e1} * and {@code e2} in the array). 数组中的元素必须实现Comparable接口 使用 有比较器我这里看的是 TimSort.sort继续看 binarySort step4哇，这里还有好多的sort啊，看的我脑袋都大了，over]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java中的transient]]></title>
    <url>%2F2018%2F08%2F10%2Fjava%E4%B8%AD%E7%9A%84transient%2F</url>
    <content type="text"><![CDATA[transient本意英 [ˈtrænziənt] 美 [ˈtrænziənt]adj. 短暂的;转瞬即逝的;临时的n. 临时旅客;瞬变现象;候鸟 序列化与反序列化要说transient，就要说序列化和反序列化维基百科的定义 序列化（serialization）在计算机科学的资料处理中，是指将数据结构或物件状态转换成可取用格式（例如存成档案，存于缓冲，或经由网络中传送），以留待后续在相同或另一台计算机环境中，能恢复原先状态的过程。依照序列化格式重新获取字节的结果时，可以利用它来产生与原始物件相同语义的副本。对于许多物件，像是使用大量参照的复杂物件，这种序列化重建的过程并不容易。面向对象中的物件序列化，并不概括之前原始物件所关联的函式。这种过程也称为物件编组（marshalling）。从一系列字节提取数据结构的反向操作，是反序列化（也称为解编组,deserialization, unmarshalling）。 序列化在计算机科学中通常有以下定义: 对同步控制而言，表示强制在同一时间内进行单一存取。 在数据储存与传送的部分是指将一个对象存储至一个储存媒介，例如档案或是记亿体缓冲等，或者透过网络传送资料时进行编码的过程，可以是字节或是XML等格式。而字节的或XML编码格式可以还原完全相等的对象。这程序被应用在不同应用程序之间传送对象，以及服务器将对象储存到档案或数据库。相反的过程又称为反序列化。 还不是很清楚，引用这篇博客说的: 序列化：将一个对象转换成一串二进制表示的字节数组，通过保存或转移这些字节数据来达到持久化的目的。 反序列化：将字节数组重新构造成对象。 java实现序列化及反序列化java中要实现对象序列化只需要实现java.io.Serializable接口，想要更深的了解Serializable接口，只需要看其相关API或javadoc即可，下面我们来捡一些我看得懂的重要内容看 Serializability of a class is enabled by the class implementing thejava.io.Serializable interface. Classes that do not implement thisinterface will not have any of their state serialized or deserialized.All subtypes of a serializable class are themselves serializable. Theserialization interface has no methods or fields and serves only toidentify the semantics of being serializable. 只有实现了Serializable接口才能序列化，所有实现了Serializable接口的类的子类也能序列化，该接口没有任何方法和属性，只是用作标识能够序列化，这种用法在java中应该还有其他的，现在没影响了。 To allow subtypes of non-serializable classes to be serialized, thesubtype may assume responsibility for saving and restoring the stateof the supertype’s public, protected, and (if accessible) packagefields. The subtype may assume this responsibility only if the classit extends has an accessible no-arg constructor to initialize theclass’s state. It is an error to declare a class Serializable if thisis not the case. The error will be detected at runtime. 大意就是上面说的，实现了Serializable接口的类的子类(没有明确实现Serializable的)要想能够序列化，那么其父类必须要有一个没有参数的子类能够访问的构造方法，下面写个简单的示例:父类没有无参构造函数，子类直接报错了，下面在父类中添加无参构造函数可以看到没报错了 Classes that require special handling during the serialization and deserialization process must implement special methods with these exact signatures: private void writeObject(java.io.ObjectOutputStream out) throws IOException; private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException; private void readObjectNoData() throws ObjectStreamException; 想要自定义序列化或反序列化的过程，需要在类中实现这些方法。 默认的序列化和反序列化的方法分别在java.io.ObjectInputStream/java.io.ObjectOutputStream中方法名称分别为defaultReadObject/defaultWriteObject The serialization runtime associates with each serializable class aversion number, called a serialVersionUID, which is used duringdeserialization to verify that the sender and receiver of a serializedobject have loaded classes for that object that are compatible withrespect to serialization. If the receiver has loaded a class for theobject that has a different serialVersionUID than that of thecorresponding sender’s class, then deserialization will result in anInvalidClassException. A serializable class can declare its ownserialVersionUID explicitly by declaring a field named“serialVersionUID” that must be static, final, and of type long: ANY-ACCESS-MODIFIER static final long serialVersionUID = 42L; 大意为每个可序列化的类必须要有一个叫做 serialVersionUID 的属性，接收端在进行反序列化时会判断序列化中对象的UID和本地的相应类的UID是否相同，如果不同会抛出InvalidClassException异常，该属性必须叫这个名字，而且是 static,final,long类型的 If a serializable class does not explicitly declare a serialVersionUID, then the serialization runtime will calculate a default serialVersionUID value for that class based on various aspects of the class, as described in the Java(TM) Object Serialization Specification. However, it is strongly recommended that all serializable classes explicitly declare serialVersionUID values, since the default serialVersionUID computation is highly sensitive to class details that may vary depending on compiler implementations, and can thus result in unexpected InvalidClassExceptions during deserialization. Therefore, to guarantee a consistent serialVersionUID value across different java compiler implementations, a serializable class must declare an explicit serialVersionUID value. It is also strongly advised that explicit serialVersionUID declarations use the private modifier where possible, since such declarations apply only to the immediately declaring class–serialVersionUID fields are not useful as inherited members. Array classes cannot declare an explicit serialVersionUID, so they always have the default computed value, but the requirement for matching serialVersionUID values is waived for array classes. 这一段很长，主要就是说这个UID很重要，如果你没有明确声明，那么jvm会在序列化时候，计算一个UID作为默认的，但是这个计算方式非常依赖编译器，并且产生的结果和这个类本身(即属性，方法什么的)有很大的关系，所以这样一来，不同的jvm对同一个类默认生成的UID可能不同，而且一旦修改了类内容，那么肯定新的UID非常可能会和旧UID不同，这样很容易导致反序列化失败，我这里做一个修改类的例子:很正常的一个类，下面是序列化和反序列化反序列化结果:然后我把Book类中的test字段删除，发送端的已经保存到dest1.txt中了，我现在修改Book类相当于是接收端修改了类，然后接收端再从dest1.txt反序列化，结果:可以看到报异常了，所以说，这个serialVersionUID还是自己声明一个比较好 transient关键字transient说来应该就是为序列化和反序列化服务的，当一个字段声明为transient时，在默认的序列化和反序列化过程中就会跳过该字段，但并不是说该字段就不能被序列化了，我们可以自定义序列化过程来使得其进行序列化，还记得前边的 writeObject/readObject方法吧，我们可以在这些方法中自定义序列化过程。这样一来，我们对于序列化的掌握就更加深了，对于一般的字段，用默认序列化方法即可，对于一些特殊的字段，比如用户密码什么的，我们可以对其声明transient，然后在自定义序列化中对其进行一些加密或其他处理在序列化。其实在上边的示例中仔细看就会发现Book类中flag字段是 transient的，但是在反序列时我依然可以读取该字段，就是因为我自定义了序列化/反序列化: 序列化扩展在上面引用的序列化定义中写道”将一个对象转换成一串二进制表示的字节数组”，那么如今我把这个二进制的字节数组写到了dest1.txt文件，那么我们为什么不看一看文件内容呢这里有两个文件，左边的dest.txt是没有自定义序列化的，右边的是自定义了序列化的，所以右边比左边多出了一个flag，值为1，下边对文件dest1.txt内容进行分析，还是参考了这篇博客 序列化文件头 AC ED：STREAM_MAGIC序列化协议 00 05：STREAM_VERSION序列化协议版本 73：TC_OBJECT声明这是一个新的对象 序列化的类的描述 72：TC_CLASSDESC声明这里开始一个新的class 00 04：十进制的4，表示class名字的长度是4个字节 42 6F 6F 6B：类名，包括包名，但是我这里没加包就没有 DB 46 ……85 65：八个字节，long类型的长度，表示serialVersionUID 03： 00 02：该类所包含的域的个数，可以看到这里不包括transient的字段 对象中各个属性项的描述 49：字符”I”，表示该属性是一个基本类型 00 06：十进制的6，表示属性名的长度 62 6F 6F 6B 49 64：字符串“bookId”，属性名 4C：字符”L”，表示该属性是一个对象类型而不是基本类型 00 08：属性名长度 八个字节：”bookName” 74：TC_STRING，代表一个new String，用String来引用对象 该对象父类的信息(这里我不是很懂) 00 12：十进制的18，表示父类的长度 4C 6A 61 … 6E 67 3B：“L/java/lang/String;”表示的是父类属性 78：TC_ENDBLOCKDATA，对象块结束的标志 70：TC_NULL，说明没有其他超类的标志 对象的属性项的实际值如果属性项是一个对象，这里还将序列化这个对象，规则和第2部分一样 00 00 00 01：bookId的值，为1，我才基本类型就直接显示值 74：前边说是代表一个new String 00 05：应该是new String 的长度 62 6F 6F 6B 31：bookName的值”book1”在后边就是自定义序列化增加的内容了 77：w，应该是标识write 04：表示写了4个字节 00 00 00 01：表示flag的值，为1 78：对象块结束的标志 额外 在自定义序列化中，可以看到上边我用的是writeInt，写4个字节，还有一个write(int)方法，只写一个字节，当参数超过一个字节时，只写低8位，看一个示例：我把上边的flag改为 77777777，很明显这个数超过8个字节了，其16进制为04a2cb71，我们看一下写到文件中的内容：只写了一个71 static变量也不会被序列化 over]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>transient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的static]]></title>
    <url>%2F2018%2F08%2F08%2Fjava%E4%B8%AD%E7%9A%84static%2F</url>
    <content type="text"><![CDATA[java中的static想必很常见了，但是若要问到其具体的用法，你又能说出几种呢 static修饰变量方法这应该是最常见的一种用法了，当类中的属性或方法被static修饰后，就变成了类属性，也就是说访问这些方法或属性不需要类的实例，直接 ClassName.fieldName/ClassName.methodName一般在访问这些静态变量或方法时，不推荐用类实例来访问示例: 12345678910111213141516171819202122232425262728293031public class StaticOne &#123; public static int flag = 123; private String hello; public void setHello(String hello) &#123; this.hello = hello; &#125; @Override public String toString() &#123; return "StaticOne&#123;" + "hello='" + hello + '\'' + "flag='" + StaticOne.flag + '\'' + '&#125;'; &#125; public static void main(String[] args) &#123; StaticOne staticOne1 = new StaticOne(); staticOne1.setHello("staticOne1"); System.out.println(staticOne1.toString()); StaticOne staticOne2 = new StaticOne(); staticOne2.setHello("staticOne2"); System.out.println(staticOne2.toString()); StaticOne.flag = 111; System.out.println(staticOne1.toString()); System.out.println(staticOne2.toString()); &#125;&#125; 运行结果: StaticOne{hello=’staticOne1’flag=’123’}StaticOne{hello=’staticOne2’flag=’123’}StaticOne{hello=’staticOne1’flag=’111’}StaticOne{hello=’staticOne2’flag=’111’} 可以看到类实例共享类静态属性，类中的静态成员变量在jvm有特定的存放位置，叫做 方法区 static修饰代码块static修饰的代码块在类被加载时就运行，而且只在类被加载到jvm中时运行一次，后续创建该类实例时不再运行示例: 12345678910111213public class StaticTwo &#123; public StaticTwo() &#123; System.out.println(System.currentTimeMillis()); &#125; static &#123; System.out.println(System.currentTimeMillis()); System.out.println("this is static block in class StaticTwo"); &#125; public static void main(String[] args) &#123; StaticTwo staticTwo1 = new StaticTwo(); StaticTwo staticTwo2 = new StaticTwo(); &#125;&#125; 运行结果: 1533725267598 this is static block in class StaticTwo15337252675981533725267598 虽然时间都是一样的，但是还是可以看到，static代码块里的代码在实例化对象之前执行，我猜静态代码块一般用来初始化一些数据用 在面试题中也会出现，父类子类里边都有静态代码块、代码块、构造函数，让你说说他们的执行顺序让我们来改造一下示例代码:123456789101112131415public class StaticTwo &#123; public StaticTwo() &#123; System.out.println("this is constructor " + System.currentTimeMillis()); &#125; static &#123; System.out.println("this is static block in class StaticTwo " + System.currentTimeMillis()); &#125; &#123; System.out.println("this is current block in class StaticTwo " + System.currentTimeMillis()); &#125; public static void main(String[] args) &#123; StaticTwo staticTwo1 = new StaticTwo(); StaticTwo staticTwo2 = new StaticTwo(); &#125;&#125; 很简单，就加了一个普通的代码块，先来看看执行结果吧: this is static block in class StaticTwo 1533725730951this is current block in class StaticTwo 1533725730951this is constructor 1533725730951this is current block in class StaticTwo 1533725730951this is constructor 1533725730951 很容易看出一些规律，在一个类中，每次新建类实例时，都会执行一遍普通代码块，再执行构造方法接着改造，加入父子类: 123456789101112131415161718192021222324252627public class StaticTwo &#123; public StaticTwo() &#123; System.out.println("this is StaticTwo constructor " + System.currentTimeMillis()); &#125; static &#123; System.out.println("this is static block in class StaticTwo " + System.currentTimeMillis()); &#125; &#123; System.out.println("this is current block in class StaticTwo " + System.currentTimeMillis()); &#125;&#125;class StaticTwoChild extends StaticTwo&#123; public StaticTwoChild() &#123; System.out.println("this is StaticTwoChild constructor " + System.currentTimeMillis()); &#125; static &#123; System.out.println("this is static block in class StaticTwoChild " + System.currentTimeMillis()); &#125; &#123; System.out.println("this is current block in class StaticTwoChild " + System.currentTimeMillis()); &#125; public static void main(String[] args) &#123; StaticTwoChild staticTwoChild1 = new StaticTwoChild(); StaticTwoChild staticTwoChild2 = new StaticTwoChild(); &#125;&#125; 运行结果: this is static block in class StaticTwo 1533726245985this is static block in class StaticTwoChild 1533726245986this is current block in class StaticTwo 1533726245986this is StaticTwo constructor 1533726245986this is current block in class StaticTwoChild 1533726245986this is StaticTwoChild constructor 1533726245986this is current block in class StaticTwo 1533726245986this is StaticTwo constructor 1533726245986this is current block in class StaticTwoChild 1533726245986this is StaticTwoChild constructor 1533726245986 分析: java中扩展类的初始化过程是这样的，最初虚拟机会依次递推找到最上层的父类，执行完类加载与静态成员的初始化；当main函数中执行代码，产生某个子类对象时，再依次递归找到最上层的父类先进行成员初始化（对象引用没有直接赋值就初始化为Null）,再调用相应的构造器产生对象，然后逐层的进行对象初始化直到最底层的子类。 所以我们可以看到，jvm在加载StaticTwoChild时，能发现它有父类StaticTwo，所以先去加载他的父类，他的父类没有显示的父类，所以就直接加载，然后在下去加载StaticTwoChild，所以输出前两行是父类静态代码块-&gt;子类静态代码块 子类在执行构造函数时，会先找父类的非默认构造方法并执行，所以下边输出结果就是先父类即StaticTwo的构造方法，再是子类即StaticTwoChild的构造方法，上边也说过了，普通代码块在每次实例化对象时都会最先执行，所以是父类普通代码块-&gt;父类构造方法-&gt;子类普通代码块-&gt;子类构造方法 static修饰内部类内部类就是在一个类的内部，像定义变量方法那样，定义一个类，就叫内部类。其实在JDK中就有很多的内部类，尤其是在集合类中，比如下边:还有很多就不放图了。这里有会涉及静态内部类和普通内部类的区别，这里简单的说几点基本的吧: 创建实例方式不同 静态内部类中只能访问外部类中静态成员，普通内部类都行 普通内部类中不能有static关键字，但是静态内部内中静不静态都行 静态类有什么用呢？我也不清楚，抄一下别人的 内部类一般只为其外部类使用； 内部类提供了某种进入外部类的窗户； 也是最吸引人的原因，每个内部类都能独立地继承一个接口，而无论外部类是否已经继承了某个接口。因此，内部类使多重继承的解决方案变得更加完整。可能还是我阅读量太少，并没有体会到内部类的精髓。 静态引入想来这也是最不常见的吧，我也不记得第一次在哪看到的了，不过还有影响的是在一个测试类中引入的断言，应该是这样的:1import static org.junit.Assert.*; 使用静态引入可以方便我们编码，比如下边的示例123456import static java.lang.System.out;public class StaticFour &#123; public static void main(String[] args) &#123; out.println(); &#125;&#125; 不用多说了吧。]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HashMap如何产生环]]></title>
    <url>%2F2018%2F07%2F31%2FHashMap%E5%A6%82%E4%BD%95%E4%BA%A7%E7%94%9F%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[HashMap本身不是线程安全的，所以高并发的情况下不应该使用HashMap，但是这里还是看了一下HashMap可能会产生的问题及其原因。这里讨论的主要是jdk1.7版本的HashMap。 参考https://mailinator.blogspot.com/2009/06/beautiful-race-condition.html 正常情况下HashMap当HashMap中的元素超过其阀值时，HashMap要进行扩容，进行resize()操作, 下边的是jdk1.7的实现 1234567891011121314151617void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K, V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K, V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125; &#125; 单线程下的resize()接下来进行resize()操作，首先e指向A，next指向B，然后把e放到新的HashMap中结束这一次迭代时把e指向B就这样循环的把每一个Entry都放到新的HashMap中最终变成这样：注意while循环的结束条件为 e==null 并发下的HashMap假设有两个线程对上边的HashMap进行操作，在他们运行时，都知道要进行resize()，首先是线程1：刚把e和next赋值，cpu就被线程2抢走了，而且线程2还比较厉害，一直把resize()完成才退出，那么线程2结束时我们的HashMap就变成这样了：这里线程2对HashMap的操作会影响线程1中的e和next，因为操作的都是同一块内存然后线程1继续执行，但是他不知道e和next的位置已经发生了变化，甚至不知道他已经不用再resize()了，需要注意的是，在resize()过程中，新表在建立过程中会把旧表中的Entry都置为null，但是线程1可不管那么多，他只知道e和next还指向内存块，他还要进行resize(). 然后线程1在线程2建立的新表的基础上继续resize()，要注意的是，此时线程1在循环之前就把他的新表建立了，线程1继续执行的效果如下把A取出放入新表中，然后e指向next即B，注意此时B的next为A，然后新一轮迭代中 1next = e.next 所以next指向了A 下一轮迭代中，e指向next即A，next指向null，然后用头插法把A插到头，结果就变成这样了！！ 虽然建表的过程就此结束了，但是新表中含有了环！！那么下次只要有查询的需求并且查到了这个环，那么就会一直查下去造成死循环！ 总结总的说来，resize()会产生环主要是把元素放到新桶中用的头插法，在1.8中已经改进了，并且1.8一般不会再产生环了。]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多设备使用hexo的实操]]></title>
    <url>%2F2018%2F07%2F23%2F%E5%A4%9A%E8%AE%BE%E5%A4%87%E4%BD%BF%E7%94%A8hexo%E7%9A%84%E5%AE%9E%E6%93%8D%2F</url>
    <content type="text"><![CDATA[前边写了如何在多终端中使用hexo写东西，今天来实际操作一把。 在寝室我就把hexo环境传到github上的hexo分支了，下面在新设备上操作 1.安装环境首先安装git、node.js、hexo，可以用git bash以linux方式操作，也可以直接去官网下Windows版(新设备是windows)。 2.clone分支然后把github上的hexo分支clone下来，完成后查看如下图： 3.安装依赖然后我们进入XXX.github.io目录下，使用命令1npm install 下载hexo需要的依赖什么，完成后如下图：可以看到多了一个 node_modules 文件夹 4.写东西然后就可以这样1hexo new 'postname' 新建，然后写吧。 5.最后最后就是部署和上传分支了，要保证分支是最新的，不然下次去了新设备你就无法获取最新的hexo分支，会丢失更新的文章，如果你再推送了新文章，那么那些丢失的文章就会在部署的时候被删除。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多终端使用hexo+Github Page写东西]]></title>
    <url>%2F2018%2F07%2F20%2F%2023-52-51%2F</url>
    <content type="text"><![CDATA[有一天，我突然想到如果我换了电脑，我要怎么继续往我的Github Page上推送新东西呢? 分析由于使用了hexo，所以肯定和hexo有关系咯。我们先来分析一下hexo的结构 _config.yml全局配置文件，网站的很多信息都在这里配置，诸如网站名称，副标题，描述，作者，语言，主题，部署等等参数。 package.jsonhexo框架的参数和所依赖插件 scaffoldsscaffolds是“脚手架、骨架”的意思，当你新建一篇文章（hexo new ‘title’）的时候，hexo是根据这个目录下的文件进行构建的，相当于是个模板。 source这个目录很重要，新建的文章都是在保存在这个目录下的。_posts 。需要新建的博文都放在_posts 目录下。 _posts 目录下是一个个 markdown 文件。你应该可以看到一个 hello-world.md 的文件，文章就在这个文件中编辑。 _posts 目录下的md文件，会被编译成html文件，放到 public文件夹下，最终部署时也是public中的文件被push到XXX.github.io的master分支下。 themes网站主题目录，hexo有非常好的主题拓展，支持的主题也很丰富。 另外还有一个文件 .gitignore，在git提交时忽略的文件，这也是一个伏笔吧。 解决我们在写文章时，其实用到的就是由这些文件组成的环境，那么只要我们有这个环境了，不就可以想在哪写在哪写吗。这里我直接用github保存这个环境，而且hexo已经给我们提供了.gitignore文件，不就在暗示我们用git提交吗。 这里你可以再创建一个仓库用来保存hexo的环境，或者直接在XXX.github.io仓库中新建一个分支，我是新建分支的。需要注意的是，新建的分支是在master的基础上建立的，所以新分支中还有我们的blog内容，其实是可以不需要的，反正我是不喜欢这两个部分混合在一起。新分支起名hexo，在setting中设置hexo为默认分支，这样方便我们提交，后面会说到。 clone XXX.github.io到本地，此时查看分支就是hexo了，然后先把所有的文件都删掉，这些文件就让他们在master中就好，然后把本地blog下的所有文件都复制到hexo分支中，也就是上面说的hexo环境复制到hexo分支中(都是hexo可别搞混了)。 把本地hexo分支同步到远程hexo分支中，git add . | git commit | git push 就是这一套，然后现在的情况，拿我的来说如下图：hexo分支master分支发现hexo分支下的文件变少了，那是因为.gitignore文件已经帮我们过滤了那些没有必要上传的文件，比如 public/ ，.deploy_git/，node_modules/ 等目录。 有了hexo环境后就好办了，当我们在一个新的设备上要写东西时，就先把hexo分支搞下来，当然新设备上需要git、node、hexo等就不说了，在clone下来的文件中没有node所需要的包什么的，我们要现下，执行命令 1npm install 完成后你会发现多了一个node_modules文件，然后应该就可以用hexo new “blog_name” 写文章了吧。。。(这里我不太确定，明天去单位电脑试试) 平时写完东西后就直接 hexo clean/generate/deploy 一套带走，然后就会发现我们的master分支已经有了新内容了，这是在_config.yml文件中配置的deploy起的作用，指定了master分支(而且Github Page也规定了要用master分支)，但是现在，不仅要更新文章，还要更新我们的hexo环境，所以我们还需要提交我们的环境到hexo分支，你看，master分支的修改我们不用去管，我们主要维护hexo分支，所以把hexo分支设置为默认分支更方便我们提交等(而且clone也比较方便，直接clone的就是hexo分支)。 稍微进一步由此我们可以总结出现在写完东西后需要做的事情，提交hexo分支(因为我们新建的文章都在hexo/source/_posts下面，所以hexo分支是必定会被改动的)，部署，一趟命令下来也不好受，那就直接把这些命令丢到脚本去吧，每次写完文章执行脚本就好了。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo每次deploy后需要重新绑定自定义域名]]></title>
    <url>%2F2018%2F07%2F20%2F%2022-30-43%2F</url>
    <content type="text"><![CDATA[在hexo目录下的source下新建一个CNAME文件，写上自定义的域名即可。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux下的nc]]></title>
    <url>%2F2018%2F07%2F20%2F%2021-45-34%2F</url>
    <content type="text"><![CDATA[NC，组内共享工具 用在linux下，主要有三个功能，扫描端口，传输文件，监控网速 这里主要说一下传输文件 环境由于是用在linux下的，我就用虚拟机来做实验，用Virtualbox建了两台Centos7 要求： 这两台机子能互相ping通 最好可以联网，因为我的Centos7没有自带nc工具 如果能ping通主机就更好了，这样可以使用xshell等连接工具，操作更方便 接下来先说说让这些机器相互ping通看了教程，用两块网卡比较方便，一块NAT，一块Host-Only，我的弊见就是NAT用来访问外网，Host-Only和主机打交道有一点要注意，启动网络连接是在你没启动虚拟机时选择的，虚拟机跑起来了就无法添加网卡了 配置虚拟机中的网卡在 /etc/sysconfig/network-scripts/ 下可以看到这样的两个网卡，ifcfg-enp0s3和ifcfg-enp0s8，分别代表NAT和Host-Only的网卡 两块网卡都要修改画红框的是需要注意的地方，Host-Only网卡中需要配置静态ip，此ip需要根据主机中VirtualBox Host-Only Network网卡的ip设置，可以看到这两个ip是处于同一个网段中的。 重启网络service network restart 这时候可以尝试ping baidu.com 和主机，注意ping主机时ping的是以太网适配器的ip而不是VirtualBox Host-Only Network的ip 然后用同样的套路在造一个Centos7现在主机和虚拟机可以互相ping通，虚拟机可以ping通外网，但是我这里虚拟机之间不能ping通了，可能是两台虚拟机的主机名是一样的？我没有细查，修改了 /etc/hosts文件然后再重启网络，虚拟机之间就可以ping通了 环境终于好了，下面用nc，我主要试了文件传输功能这里需要注意的是我新造的虚拟机是开启了防火墙的，所以下边监听端口的话，要先开发该端口，所以有涉及到Centos7开放端口12firewall-cmd --zone=public --add-port=9999/tcp --permanentfirewall-cmd reload #刷新规则 1nc -l 9999 &gt; test.txt 机器A监听9999端口，当有动静的时候，把收到的内容写到test.txt文件中 1nc 192.168.56.100 9999 &lt; hello.txt 机器B使用nc把hello.txt 传送给机器A，机器A把hello.txt中的内容写入到test.txt中 当然也可以翻转一下1nc -l 9999 &lt; hello.txt 这样当有人连接该端口时，就把hello.txt发给他 个人感觉传输功能比较使用，可能是我眼界现在还太狭隘了，没有理解其他功能的实际用处。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX删除查找到的所有文件及目录]]></title>
    <url>%2F2018%2F07%2F08%2F%2011-37-13%2F</url>
    <content type="text"><![CDATA[这里需要用find命令，因为find命令后边可以跟其他可执行的命令 Step1. 首先根据关键字查找特定的文件及目录我这里用steam作示范，这样就能找到所有包含’steam’关键字的文件及目录 Step2. 在后边追加操作命令1) 追加命令格式为: -exec command {} \;在{}和\之间必须要有空格，否则会报错. 2) xargs用于从 标准输入获得参数并且传递给后面的命令，这里使用的命令是 rm，然后由rm删除前面选择的文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KMP算法中求NEXT时回溯?]]></title>
    <url>%2F2018%2F06%2F30%2F%2021-32-58%2F</url>
    <content type="text"><![CDATA[在网上看ＫＭＰ算法相关的博客时，在求next数组时基本上都会有这么一句: k = next[k-1] 或者 k = next[k] 该赋值语句在判断 当前字符 不等于 当前字符的前一个字符的相同前缀的 后一个字符时 用到， 用语言来描述不太方便，画图试试 真的是太神奇了，使用k = next[k-1] 或 k=next[k]，就可以保证用最快方式找到应该和 “d” 进行比较的位置，丝毫不拖泥带水，我只能说太巧妙了。 像上边这个串，第二次比较后还是不一样，那么k就等于-1，退出循环，说明再往前找就找不到和 ”d” 前边一样的前缀了，所以 ”d” 下边也是-1，即没有匹配的前后缀。 这个玩意我断断续续想了两天，突然就懂了一些，不得不说”看毛片”还是难啊。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>KMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA之ERROR/EXCEPTION]]></title>
    <url>%2F2018%2F06%2F24%2F%2023-24-09%2F</url>
    <content type="text"><![CDATA[java异常分为Error和Exception，二者都是继承自Throwable 先来看看Exception： The class Exception and its subclasses are a form of Throwable thatindicates conditions that a reasonable application might want tocatch. The class Exception and any subclasses that are not also subclasses ofRuntimeException are checked exceptions. Checked exceptions need to bedeclared in a method or constructor’s throws clause if they can bethrown by the execution of the method or constructor and propagateoutside the method or constructor boundary. 可以知道Exception的子类除了RuntimeException 都是检查型异常，在程序中需要捕获处理或者抛给上层处理。 再看看RuntimeException RuntimeException is the superclass of those exceptions that can bethrown during the normal operation of the Java Virtual Machine. RuntimeException and its subclasses are unchecked exceptions.Unchecked exceptions do not need to be declared in a method orconstructor’s throws clause if they can be thrown by the execution ofthe method or constructor and propagate outside the method orconstructor boundary. 可以看到不要求在编译的时候处理。 Error的定义 An Error is a subclass of Throwable that indicates serious problemsthat a reasonable application should not try to catch. Most sucherrors are abnormal conditions. The ThreadDeath error, though a“normal” condition, is also a subclass of Error because mostapplications should not try to catch it. A method is not required to declare in its throws clause anysubclasses of Error that might be thrown during the execution of themethod but not caught, since these errors are abnormal conditions thatshould never occur. That is, Error and its subclasses are regarded asunchecked exceptions for the purposes of compile-time checking ofexceptions. Error是程序中严重的错误，任何合理的程序都不能去捕获Error。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>error/exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NETSTAT 命令]]></title>
    <url>%2F2018%2F06%2F22%2F%2011-20-01%2F</url>
    <content type="text"><![CDATA[Print network connections, routing tables, interface statistics,masquerade connections, and multicast memberships netstat用来显示网络相关的信息，如网络连接，路由表，接口统计，伪装链接和广播成员 常用的几个选项 –numeric , -n Show numerical addresses instead of trying to determinesymbolic host,port or user names. 不解析名称，显示数字就行 -p, –program Show the PID and name of the program to which each socket belongs. 显示端口(?)所属的程序的pid和名字 -l, –listening Show only listening sockets. (These are omitted by default.) 只显示正在监听的端口 {-t|–tcp} {-u|–udp} 分别表示显示TCP/UDP传输协议的连接 一些在我看来很高级的用法：查看连接某服务端口最多的的IP地址： netstat -ntu | grep :80 | awk ‘{print $5}’ | cut -d: -f1 | awk‘{++ip[$1]} END {for(i in ip) print ip[i],”\t”,i}’ | sort -nr TCP各种状态列表： netstat -nt | grep -e 127.0.0.1 -e 0.0.0.0 -e ::: -v | awk ‘/^tcp/{++state[$NF]} END {for(i in state) print i,”\t”,state[i]}’ 查看phpcgi进程数，如果接近预设值，说明不够用，需要增加： netstat -anpo | grep “php-cgi” | wc -l]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>netstat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA编辑POM文件时没有提示]]></title>
    <url>%2F2018%2F06%2F21%2F%2016-15-21%2F</url>
    <content type="text"><![CDATA[这需要我们更新IDEA中maven 的repositories 如下图： 选中本地仓库点击右边的更新，这样再编辑pom文件时就会提示你本地仓库中所含有的坐标]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GIT CLONE BRANCH]]></title>
    <url>%2F2018%2F06%2F20%2F%2022-09-50%2F</url>
    <content type="text"><![CDATA[在使用git clone项目后，查看本地分支，只有master分支，远程仓库的其他分支并没有克隆下来，如果需要其他分支可以用下面两种方法 方法一git branch -a 先查看当前远端分支情况 git checkout origin/xxx 选择远端xxx分支 git branch xxx 创建本地xxx分支 git checkout xxx 选择新创建的分支就可以了 方法二git clone -b]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>clone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TRY REDIS中的命令]]></title>
    <url>%2F2018%2F06%2F12%2F%2021-02-16%2F</url>
    <content type="text"><![CDATA[中文官方网站对其的介绍： Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets）与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRUeviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。 GET/SET Redis is what is called a key-value store, often referred to as aNoSQL database. The essence of a key-value store is the ability tostore some data, called a value, inside a key. This data can later beretrieved only if we know the exact key used to store it. We can usethe command SET to store the value “fido” at key “server:name” 用 SET 对key进行赋值用 GET 获取key的value. DEL Other common operations provided by key-value stores are DEL to deletea given key and associated value, SET-if-not-exists (called SETNX onRedis) that sets a key only if it does not already exist, and INCR toatomically increment a number stored at a given key 用DEL 删除一个变量后，查询该变量变为 nil，意思为”空，零”INCR在Redis中为自加1操作，为原子性的操作. LIVE TIME Redis can be told that a key should only exist for a certain length oftime. This is accomplished with the EXPIRE and TTL commands. 用EXPIRE 规定key的存在时长，单位为秒(默认)用TTL查看key还剩多久删除 The -2 for the TTL of the key means that the key does not exist (anymore). A -1 for the TTL of the key means that it will never expire. Note that if you SET a key, its TTLwill be reset. LIST Redis also supports several more complex data structures. The firstone we’ll look at is a list. A list is a series of ordered values.Some of the important commands for interacting with lists are RPUSH,LPUSH, LLEN, LRANGE, LPOP, and RPOP. You can immediately begin workingwith a key as a list, as long as it doesn’t already exist as adifferent type. RPUSH：放在list的右边LLEN：list的长度LRANGE：显示从start到end的数据LPOP：删除最左边的元素 SET The next data structure that we’ll look at is a set. A set is similarto a list, except it does not have a specific order and each elementmay only appear once. Some of the important commands in working withsets are SADD, SREM, SISMEMBER, SMEMBERS and SUNION. SADD：添加元素SREM：移除元素SISMEMBER：判断set是否包含某一元素SMEMBERS：打印set内容SUNION：合并打印多个set SORTED SETS Sets are a very handy data type, but as they are unsorted they don’twork well for a number of problems. This is why Redis 1.2 introducedSorted Sets. A sorted set is similar to a regular set, but now each value has anassociated score. This score is used to sort the elements in the set. 可以通过设定的score进行排序的setZADD：添加元素 (exp. ZADD hackers 1940 “Alan Kay”)ZRANGE：升序ZREVRANGE：降序 HASHESHashes：用来存放对象很好HSET：存放对象属性和值 (HSET user:1000 name “John Smith”)HGETALL：获取对象的所有属性和值HGET：获取对象某个属性的值HINCRBY：指定对象某个数字属性的值加上HDEL：删除对象某个属性]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LINUX下的JOB, FG, BG, &]]></title>
    <url>%2F2018%2F06%2F12%2F%2019-59-58%2F</url>
    <content type="text"><![CDATA[在使用linux过程中，偶尔会不自觉的按ctrl + z，这时候会显示[1]+ Stopped 之类的，而且如果这时候你在做一些操作，比如编辑文件等，会直接回到命令状态。那么之前的工作去哪了呢? 去了Stopped于后台中了。 这是输入jobs命令，就可以查看Linux中的任务列表及任务状态，包括后台运行的任务。 bg(background) 将后台暂停的任务启动，在后台继续运行 fg(foreground) 将后台任务调至前台执行 &amp; 放在命令的最后，用于将任务放在后台执行]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>background</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git push]]></title>
    <url>%2F2018%2F05%2F24%2F%2010-44-57%2F</url>
    <content type="text"><![CDATA[现在的情况是，本地有两个分支：master、div， 远程仓库有一个分支：master，本地master分支和远程master分支建立有跟踪联系，这样本地master分支提交时直接git push(只有一个远程仓库的情况下) 那么div分支也想提交到远程master怎么办呢，先试试直接git push：提示信息很清楚了 这里使用命令 git push origin HEAD:master 即可 而HEAD指向的是当前的分支，git可以通过HEAD找到当前的分支名，所以该命令相当于 git push origin div:master ==git push/pull &lt;远程主机名&gt; &lt;源分支&gt;:&lt;目的分支&gt;== 是git push常用的精简命令的完整格式，当然还可以加git push的各种 []，这里就不说了。 说实话，我平时只顾着用git push ，连git push不省略的格式是什么都不记得了，唉. 2018.06.20 更新 在推送前，我们可以使用命令 git push -u &lt;远程主机名&gt; &lt;分支名&gt; 其中-u 参数效果：如果当前分支与多个主机存在追踪关系，则可以使用-u选项指定一个默认主机，这样后面就可以不加任何参数使用git push. –set-upstream 是用来和远程分支建立追踪关系]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>push</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX下配置环境变量]]></title>
    <url>%2F2018%2F05%2F21%2F%2010-37-48%2F</url>
    <content type="text"><![CDATA[有些东西不自己写一下，总是会忘记，当然写了也可能还是会忘，但是找起来印象会深一点吧。之前在需要配置环境变量的时候就直接查了一下，完成配置后就没管了，最近再次想到这个问题，结果已经忘记该怎么配置了。所以什么东西都是写一下比较好吧. 方式一：使用export使用export命令直接修改PATH变量 方式二：修改/etc/profile 如果要立即生效需要执行命令 source /etc/profile 使用这种方式，所有用户都会受影响,当第一个用户登录时,该文件被执行. 类似的还有/etc/enviroment文件，影响所有用户 方式三：修改~/.bashrc 同样立即生效需要： source ~/.bashrc 专属于个人bash shell的信息，当该用户登录时以及每次打开新的shell时,该文件被读取. 类似的还有~/.profile，当用户登录时,该文件仅仅执行一次!默认情况下,它设置一些环境变量,然后执行用户的.bashrc文件.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>path</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[笔记本安装SSD, 并在SSD中安装系统]]></title>
    <url>%2F2018%2F05%2F02%2F%2008-49-01%2F</url>
    <content type="text"><![CDATA[前言很早就想买个ssd了，经过一些事情之后，我也没那么多顾虑，想买就买了。本来打算是在ssd中重装一个系统的，但是后来考虑到电脑里边有些东西重装系统后再搞很麻烦，就没有选择重装系统了，但是突然想试试Linux，就选了Ubuntu，安在了ssd里边，把电脑搞成双系统，所以这篇文章有这几个部分吧：笔记本安装ssd、安装Ubuntu系统、笔记本实现双系统。 笔记本装ssd我的笔记本没有空出的位置装ssd，所以就把光驱拆了，买ssd时候把电脑型号发给客服，客服会告诉你用什么规格的支架。然后就是拆光驱，把ssd放进支架里，在把支架安在原来放光驱的地方，挺简单的。 对了，还有关于笔记本是否能发挥ssd性能的几个小点，首先是接口，就是光驱那个接口最好是sata3接口的; 然后是bios里有个地方IDE要设置成 AHCI模式。 装好之后可以下载一些测试工具，这里我忘了我用的啥了，查一下就知道。 安装Ubuntu系统我用的是u盘作为启动盘，所以这里就讲讲这种方式。 首先下载ubuntu系统iso， 然后用UltraISO制作启动盘，制作好后，保持u盘插入的状态，重启电脑，这时候要进入BIOS系统(具体按哪个键可以搜一下，我的华硕是F2)，在BIOS中更改启动盘，选择刚刚的u盘，应该会有名字的。 启动之后应该就是安装的界面了，具体安装过程怎么选择我也忘了，这里没有截图，捡我记得的写。我在安装过程中，提示过我一个东西，好像是有个格式不对，我选择的跳过还是什么的，反正不是确认。我那时候出现这个问题，就去google了，说是启动盘要用一个别的软件做才行，然后我信了他的邪，重新一边还是这样。后边再有印象的就是分区了。 首先说明一点，分区分区，分的是你电脑里，没有进行过初始化的区域，当你的ssd刚安电脑里的时候，你用硬盘管理看到这块磁盘是未分配状态的，那么在安装系统过程中就会使用这些未分配的区域。 Linux分区，应该是安装系统中比较重要的一点？我也是按照网上的一般教程进行分区的，分了四个区: /, /boot, /home, /swap， 另外在分区时，需要注意的是swap分区需要选择”交换空间”，其他三个就按默认的Ext4日志文件系统。在说一下这四个分区的含义：/，主分区相当于windows的c盘; /boot 引导分区; /home 用户存储数据用，需要大一点; /swap 相当于电脑的内存，设置为内存的1.5～2倍。分区设置完毕后，下方还有一项“安装启动引导器的设备”，默认是ubuntu引导windows，也就是开机启动显示的ubuntu的样子，然后选择是ubuntu还是window，如果想windows引导ubuntu，则“引导器的设备”选择之前/boot分区的名字。 实现双系统前面的说明了，我是从windows引导ubuntu的，所以还需要一些工具来设置ubuntu的启动选项，这里我用的是EasyBCD，打开easyBCD，选择add new entry，选择linux/BSD，name那里填Ubuntu（可自行填写）。device(驱动器)这一栏选择我们刚创建的“/boot”分区（200MB那个，可能大小会有一点出入）。最后点击Add entry（添加条目）。最后还有一点可能会出错的地方，就是设置了引导后，选择ubuntu却无法正常启动，具体原因我不记得了，应该是在新建ubuntu条目时有个选项有问题，具体是什么，我后面在看看。 好了，大概就是这样了，有很多东西没有讲清楚，因为google一下总会有讲的清楚的，我在这里也只是理了一下我做这些事情的一个过程，就是一个简单的思路。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>ssd</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
</search>
